{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0DRUyTEgosh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torchvision.models import vgg19"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VAtCWTLxDvxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dtry):\n",
        "    super().__init__()\n",
        "    self.dtry = dtry\n",
        "    self.images = os.listdir(self.dtry)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = torchvision.io.read_image(os.path.join(self.dtry,self.images[idx]))\n",
        "    high_res_img = torchvision.transforms.RandomCrop((96, 96))(img)\n",
        "    low_res_img = torchvision.transforms.Resize((24,24))(high_res_img)\n",
        "    high_res_img = high_res_img/255.0\n",
        "    low_res_img = low_res_img/255.0\n",
        "    return high_res_img, low_res_img"
      ],
      "metadata": {
        "id": "bOW4fZpmf4e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, disc, use_bn, use_act, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    super().__init__()\n",
        "    modules = []\n",
        "    modules.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
        "    if use_bn: modules.append(nn.BatchNorm2d(out_channels))\n",
        "    if use_act:\n",
        "      if disc: modules.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "      else: modules.append(nn.PReLU(num_parameters=out_channels))\n",
        "    self.layers = nn.Sequential(*modules)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "  def __init__(self, in_channels, scale_factor):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, in_channels * scale_factor**2, 3, 1, 1)\n",
        "    self.ps = nn.PixelShuffle(scale_factor)\n",
        "    self.act = nn.PReLU(in_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.act(self.ps(self.conv(x)))\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super().__init__()\n",
        "    self.block1 = ConvBlock(disc=False, use_bn=True, use_act=True,  in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.block2 = ConvBlock(disc=False, use_bn=True, use_act=False, in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.block1(x)\n",
        "    out = self.block2(x)\n",
        "    return out+x"
      ],
      "metadata": {
        "id": "mfsgL3lBguWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, in_channels=3, n_channels=64, n_blocks=16):\n",
        "    super().__init__()\n",
        "    self.initial = ConvBlock(disc=False, use_bn=True, use_act=True, in_channels=in_channels, out_channels=n_channels, kernel_size=9, stride=1, padding=4)\n",
        "    self.residuals = nn.Sequential(*[ResidualBlock(n_channels) for _ in range(n_blocks)])\n",
        "    self.conv = ConvBlock(disc=False, use_bn=True, use_act=False, in_channels=n_channels, out_channels=n_channels, kernel_size=9, stride=1, padding=4)\n",
        "    self.upsample = nn.Sequential(UpsampleBlock(n_channels, 2),UpsampleBlock(n_channels, 2))\n",
        "    self.final = nn.Conv2d(n_channels, in_channels, 9, 1, 4)\n",
        "\n",
        "  def forward(self, x):\n",
        "    initial = self.initial(x)\n",
        "    x = self.residuals(initial)\n",
        "    x = self.conv(x) + initial\n",
        "    x = self.upsample(x)\n",
        "    x = self.final(x)\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
        "    super().__init__()\n",
        "    blocks = []\n",
        "    for idx, feature in enumerate(features):\n",
        "      blocks.append(ConvBlock(disc=True, use_bn=False if idx==0 else True, use_act=True, in_channels=in_channels,\\\n",
        "                              out_channels=feature, kernel_size=3, stride=1+(idx%2), padding=1))\n",
        "      in_channels = feature\n",
        "    self.layers = nn.Sequential(*blocks)\n",
        "    self.classifier = nn.Sequential(nn.AdaptiveAvgPool2d((6,6)),\\\n",
        "                                    nn.Flatten(),\\\n",
        "                                    nn.Linear(512*6*6,1024),\\\n",
        "                                    nn.LeakyReLU(0.2,inplace=True),\\\n",
        "                                    nn.Linear(1024,1), \\\n",
        "                                    nn.Sigmoid())\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "H9CPxniuhIPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.vgg = vgg19(pretrained=True).features[:36].eval().to(device)\n",
        "    self.loss = nn.MSELoss()\n",
        "\n",
        "    for param in self.vgg.parameters():\n",
        "      param.requires_grad = False\n",
        "  \n",
        "  def forward(self, y, y_hat):\n",
        "    vgg_y = self.vgg(y)\n",
        "    vgg_y_hat = self.vgg(y_hat)\n",
        "    return self.loss(vgg_y, vgg_y_hat)"
      ],
      "metadata": {
        "id": "RF0kkXI1Vedz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SRGAN:\n",
        "  def __init__(self,args):\n",
        "    super().__init__()\n",
        "    self.n_epochs = args['n_epochs']\n",
        "    self.dtry = args['dtry']\n",
        "    self.batch_size = args['batch_size']\n",
        "    self.dataset = args['dataset']\n",
        "\n",
        "    self.data_loader = torch.utils.data.DataLoader(self.dataset, self.batch_size, num_workers=4)\n",
        "\n",
        "    self.G = Generator().to(device)\n",
        "    self.D = Discriminator().to(device)\n",
        "    self.G.train()\n",
        "    self.D.train()\n",
        "    if 'SRGAN_G.pkl' in os.listdir(self.dtry):\n",
        "      self.load(G=True, D=True)\n",
        "    self.G_optim = torch.optim.Adam(self.G.parameters(), lr=args['lrG'], betas=(args['beta1'], args['beta2']))\n",
        "    self.D_optim = torch.optim.Adam(self.D.parameters(), lr=args['lrD'], betas=(args['beta1'], args['beta2']))\n",
        "    self.vgg_loss = VGGLoss()\n",
        "    self.bce = nn.BCELoss()\n",
        "\n",
        "  def train(self):\n",
        "    for epoch in range(self.n_epochs):\n",
        "      loop = tqdm(self.data_loader,  position=0, leave=True)\n",
        "\n",
        "      for y, x in loop:\n",
        "        y = y.to(device)\n",
        "        x = x.to(device)\n",
        "        y_hat = self.G(x)\n",
        "        real = self.D(y)\n",
        "        fake = self.D(y_hat.detach())\n",
        "\n",
        "        # update D network\n",
        "        D_loss = self.bce(real, torch.ones_like(real)) + self.bce(fake, torch.zeros_like(fake))\n",
        "        self.D_optim.zero_grad()\n",
        "        D_loss.backward()\n",
        "        self.D_optim.step()\n",
        "\n",
        "        # update G network\n",
        "        fake = self.D(y_hat)\n",
        "        adversarial_loss = 1e-3 * self.bce(fake, torch.ones_like(fake))\n",
        "        perceptual_loss = 0.006 * self.vgg_loss(y, y_hat)\n",
        "        G_loss = adversarial_loss + perceptual_loss\n",
        "        self.G_optim.zero_grad()\n",
        "        G_loss.backward()\n",
        "        self.G_optim.step()\n",
        "\n",
        "        loop.set_postfix(loss=(G_loss.item(),D_loss.item()))\n",
        "      self.save()\n",
        "    self.save()\n",
        "\n",
        "  def test(self, x):\n",
        "    y_hat = self.G(x)\n",
        "    return y_hat\n",
        "\n",
        "  def save(self):\n",
        "    torch.save(self.G.state_dict(), os.path.join(self.dtry,'SRGAN_G.pkl'))\n",
        "    torch.save(self.D.state_dict(), os.path.join(self.dtry,'SRGAN_D.pkl'))\n",
        "  \n",
        "  def load(self, G, D):\n",
        "    self.G.load_state_dict(torch.load(os.path.join(self.dtry,'SRGAN_G.pkl')))\n",
        "    self.D.load_state_dict(torch.load(os.path.join(self.dtry,'SRGAN_D.pkl')))"
      ],
      "metadata": {
        "id": "ZLrDoy81DKsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('drive/MyDrive/Carvana/train')\n",
        "args = {'dtry':'drive/MyDrive/Carvana','n_epochs':10,'batch_size':64,\\\n",
        "        'dataset':dataset,'lrG':1e-4,'lrD':1e-4,'beta1':0.9,'beta2':0.999}\n",
        "model = SRGAN(args)\n",
        "model.train()"
      ],
      "metadata": {
        "id": "nSKsnmM0BCRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "dtry = 'drive/MyDrive/Carvana/train'\n",
        "images = os.listdir(dtry)\n",
        "high_res_img = torchvision.io.read_image(os.path.join(dtry,images[idx]))/255.0\n",
        "low_res_img  = torchvision.transforms.Resize((high_res_img.shape[1]//4,high_res_img.shape[2]//4))(high_res_img)\n",
        "low_res_img = low_res_img.unsqueeze(0)\n",
        "high_res_img_hat = model.test(low_res_img.to(device))\n",
        "high_res_img_hat = high_res_img_hat.squeeze(0)"
      ],
      "metadata": {
        "id": "pymKX83UDeyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}